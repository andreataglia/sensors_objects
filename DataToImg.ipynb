{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc   #Gabage collector for cleaning deleted data from memory\n",
    "\n",
    "COL_VALUES = [\"x\", \"y\", \"z\"] #always obj at the end\n",
    "\n",
    "data=pd.read_csv(\"data/data_out_full.csv\", names = COL_VALUES + [\"obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000002</th>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000003</th>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000004</th>\n",
       "      <td>98</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000005</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000006</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000007</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000008</th>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000009</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000010</th>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x  y  z  obj\n",
       "1000000   98  6  4    1\n",
       "1000001  104  6  0    1\n",
       "1000002  109  2 -1    1\n",
       "1000003  101  8 -3    1\n",
       "1000004   98 -1 -2    1\n",
       "1000005  107  0 -2    1\n",
       "1000006  107  3  3    1\n",
       "1000007  101  0  0    1\n",
       "1000008  103  8 -4    1\n",
       "1000009  106  3  0    1\n",
       "1000010  105  5 -2    1"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1000000:1000010,['x','y','z','obj']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157815</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157816</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157817</th>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157818</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157819</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157820</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157821</th>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157822</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157823</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157824</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.455172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157825</th>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157826</th>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157827</th>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157828</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.434483</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157829</th>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157830</th>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157831</th>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.434483</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157832</th>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157833</th>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157834</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157835</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.468966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157836</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157837</th>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157838</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157839</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157840</th>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157841</th>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157842</th>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.451724</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157843</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157844</th>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.468966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1064227 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x         y         z  obj\n",
       "0        0.492537  0.220930  0.441379    2\n",
       "1        0.388060  0.302326  0.444828    2\n",
       "2        0.417910  0.302326  0.448276    2\n",
       "3        0.402985  0.372093  0.448276    2\n",
       "4        0.447761  0.337209  0.451724    2\n",
       "5        0.417910  0.290698  0.444828    2\n",
       "6        0.447761  0.279070  0.441379    2\n",
       "7        0.432836  0.279070  0.448276    2\n",
       "8        0.447761  0.302326  0.451724    2\n",
       "9        0.447761  0.325581  0.441379    2\n",
       "10       0.567164  0.290698  0.448276    2\n",
       "11       0.388060  0.302326  0.448276    2\n",
       "12       0.462687  0.348837  0.451724    2\n",
       "13       0.477612  0.302326  0.448276    2\n",
       "14       0.447761  0.290698  0.455172    2\n",
       "15       0.373134  0.313953  0.448276    2\n",
       "16       0.432836  0.232558  0.448276    2\n",
       "17       0.432836  0.290698  0.458621    2\n",
       "18       0.432836  0.325581  0.448276    2\n",
       "19       0.477612  0.302326  0.451724    2\n",
       "20       0.447761  0.325581  0.444828    2\n",
       "21       0.447761  0.267442  0.448276    2\n",
       "22       0.373134  0.290698  0.444828    2\n",
       "23       0.417910  0.244186  0.444828    2\n",
       "24       0.432836  0.395349  0.444828    2\n",
       "25       0.402985  0.313953  0.451724    2\n",
       "26       0.462687  0.325581  0.448276    2\n",
       "27       0.477612  0.302326  0.444828    2\n",
       "28       0.447761  0.302326  0.441379    2\n",
       "29       0.492537  0.313953  0.441379    2\n",
       "...           ...       ...       ...  ...\n",
       "2157815  0.477612  0.779070  0.444828    2\n",
       "2157816  0.597015  0.732558  0.448276    2\n",
       "2157817  0.462687  0.755814  0.455172    2\n",
       "2157818  0.507463  0.732558  0.444828    2\n",
       "2157819  0.477612  0.790698  0.444828    2\n",
       "2157820  0.537313  0.720930  0.448276    2\n",
       "2157821  0.462687  0.697674  0.455172    2\n",
       "2157822  0.507463  0.709302  0.455172    2\n",
       "2157823  0.552239  0.732558  0.451724    2\n",
       "2157824  0.567164  0.720930  0.455172    2\n",
       "2157825  0.552239  0.651163  0.451724    2\n",
       "2157826  0.597015  0.732558  0.462069    2\n",
       "2157827  0.432836  0.779070  0.451724    2\n",
       "2157828  0.477612  0.755814  0.434483    2\n",
       "2157829  0.522388  0.697674  0.451724    2\n",
       "2157830  0.522388  0.697674  0.444828    2\n",
       "2157831  0.492537  0.732558  0.434483    2\n",
       "2157832  0.477612  0.813953  0.441379    2\n",
       "2157833  0.582090  0.686047  0.451724    2\n",
       "2157834  0.507463  0.709302  0.441379    2\n",
       "2157835  0.507463  0.732558  0.468966    2\n",
       "2157836  0.373134  0.802326  0.444828    2\n",
       "2157837  0.507463  0.779070  0.458621    2\n",
       "2157838  0.537313  0.767442  0.441379    2\n",
       "2157839  0.447761  0.732558  0.458621    2\n",
       "2157840  0.492537  0.779070  0.451724    2\n",
       "2157841  0.522388  0.813953  0.444828    2\n",
       "2157842  0.462687  0.697674  0.451724    2\n",
       "2157843  0.537313  0.744186  0.444828    2\n",
       "2157844  0.537313  0.720930  0.468966    2\n",
       "\n",
       "[1064227 rows x 4 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in COL_VALUES:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "data=normalize(data)\n",
    "df1=data[data['obj'] == 1]\n",
    "df2=data[data['obj'] == 2]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56006\n",
      "53211\n"
     ]
    }
   ],
   "source": [
    "X = [] # images\n",
    "y = [] # labels\n",
    "ROWS = 20\n",
    "\n",
    "#create the images for each objects\n",
    "\n",
    "#obj 1\n",
    "for i in range(0,df1.shape[0]-ROWS,ROWS):\n",
    "    X.append((df1.iloc[i:i+ROWS,0:3]).values.tolist())\n",
    "    y.append(0)\n",
    "lenX = len(X)\n",
    "print(len(X))\n",
    "\n",
    "#obj 2\n",
    "for i in range(0,df2.shape[0]-ROWS,ROWS):\n",
    "    X.append((df2.iloc[i:i+ROWS,0:3]).values.tolist())\n",
    "    y.append(1)\n",
    "print(len(X)-lenX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "a = unison_shuffled_copies(np.array(X), np.array(y))\n",
    "X = a[0]\n",
    "y = a[1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5074626865671642, 0.6744186046511628, 0.4586206896551724],\n",
       " [0.44776119402985076, 0.686046511627907, 0.45517241379310347],\n",
       " [0.5074626865671642, 0.686046511627907, 0.45517241379310347],\n",
       " [0.4626865671641791, 0.6976744186046512, 0.4413793103448276],\n",
       " [0.417910447761194, 0.6046511627906976, 0.4517241379310345],\n",
       " [0.5373134328358209, 0.7441860465116279, 0.4379310344827586],\n",
       " [0.4925373134328358, 0.686046511627907, 0.46551724137931033],\n",
       " [0.43283582089552236, 0.7093023255813954, 0.4482758620689655],\n",
       " [0.5074626865671642, 0.686046511627907, 0.4379310344827586],\n",
       " [0.5074626865671642, 0.7209302325581395, 0.4379310344827586],\n",
       " [0.5373134328358209, 0.6976744186046512, 0.4482758620689655],\n",
       " [0.47761194029850745, 0.6976744186046512, 0.45517241379310347],\n",
       " [0.5223880597014925, 0.6511627906976745, 0.4379310344827586],\n",
       " [0.4626865671641791, 0.7093023255813954, 0.4586206896551724],\n",
       " [0.4925373134328358, 0.6511627906976745, 0.43448275862068964],\n",
       " [0.47761194029850745, 0.6744186046511628, 0.4482758620689655],\n",
       " [0.5522388059701493, 0.7558139534883721, 0.44482758620689655],\n",
       " [0.5522388059701493, 0.6976744186046512, 0.4379310344827586],\n",
       " [0.5522388059701493, 0.6976744186046512, 0.4517241379310345],\n",
       " [0.5223880597014925, 0.686046511627907, 0.4482758620689655]]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(X[30000+i*20])\n",
    "    print(y[30000+i*20])\n",
    "X[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of all images is:', (109217, 20, 3))\n",
      "('Shape of all labels is:', (109217,))\n",
      "('Shape of train images is:', (87373, 20, 3))\n",
      "('Shape of validation images is:', (21844, 20, 3))\n",
      "('Shape of train labels is:', (87373,))\n",
      "('Shape of validation labels is:', (21844,))\n"
     ]
    }
   ],
   "source": [
    "#Convert list to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Shape of all images is:\", X.shape)\n",
    "print(\"Shape of all labels is:\", y.shape)\n",
    "\n",
    "#Lets split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "\n",
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of validation images is:\", X_val.shape)\n",
    "print(\"Shape of train labels is:\", y_train.shape)\n",
    "print(\"Shape of validation labels is:\", y_val.shape)\n",
    "\n",
    "#clear memory\n",
    "del X\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "#get the length of the train and validation data\n",
    "ntrain = len(X_train)\n",
    "nval = len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 32, 18, 1)         320       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 18, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 74,434\n",
      "Trainable params: 74,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, Convolution2D, MaxPooling2D)\n",
    " \n",
    " \n",
    "## Some model and data processing constants\n",
    " \n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "nb_epoch = 12\n",
    " \n",
    "# input image dimensions\n",
    "img_rows, img_cols = 20, 3\n",
    " \n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    " \n",
    "model = Sequential() \n",
    " \n",
    "model.add(layers.Conv2D(32, (3, 3), padding=\"valid\", input_shape=(1, 20, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87373 samples, validate on 21844 samples\n",
      "Epoch 1/10\n",
      "87373/87373 [==============================] - 11s 127us/step - loss: 0.4298 - acc: 0.7690 - val_loss: 0.3049 - val_acc: 0.7937\n",
      "Epoch 2/10\n",
      "87373/87373 [==============================] - 11s 121us/step - loss: 0.3075 - acc: 0.8426 - val_loss: 0.2271 - val_acc: 0.8877\n",
      "Epoch 3/10\n",
      "87373/87373 [==============================] - 11s 122us/step - loss: 0.2411 - acc: 0.8903 - val_loss: 0.1704 - val_acc: 0.9314\n",
      "Epoch 4/10\n",
      "87373/87373 [==============================] - 11s 126us/step - loss: 0.1758 - acc: 0.9311 - val_loss: 0.1467 - val_acc: 0.9473\n",
      "Epoch 5/10\n",
      "87373/87373 [==============================] - 11s 123us/step - loss: 0.1610 - acc: 0.9384 - val_loss: 0.1758 - val_acc: 0.9228\n",
      "Epoch 6/10\n",
      "87373/87373 [==============================] - 11s 126us/step - loss: 0.1515 - acc: 0.9429 - val_loss: 0.1339 - val_acc: 0.9463\n",
      "Epoch 7/10\n",
      "87373/87373 [==============================] - 11s 125us/step - loss: 0.1492 - acc: 0.9432 - val_loss: 0.1288 - val_acc: 0.9523\n",
      "Epoch 8/10\n",
      "87373/87373 [==============================] - 11s 130us/step - loss: 0.1451 - acc: 0.9449 - val_loss: 0.1252 - val_acc: 0.9509\n",
      "Epoch 9/10\n",
      "87373/87373 [==============================] - 11s 125us/step - loss: 0.1435 - acc: 0.9454 - val_loss: 0.1212 - val_acc: 0.9542\n",
      "Epoch 10/10\n",
      "87373/87373 [==============================] - 11s 125us/step - loss: 0.1401 - acc: 0.9472 - val_loss: 0.1184 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cffd96d90>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size, \n",
    "          epochs=10, verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10642493, 0.893575  ]], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#try predict from the validation set\n",
    "num = 14\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    print(y_val[num+i])\n",
    "    plt.imshow(X_val[num+i][0])\n",
    "    \n",
    "x = np.expand_dims(X_val[num], axis=0)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try predict from external data\n",
    "data=pd.read_csv(\"data/data_val.csv\", names = COL_VALUES + [\"obj\"])\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in COL_VALUES:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "data=normalize(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
